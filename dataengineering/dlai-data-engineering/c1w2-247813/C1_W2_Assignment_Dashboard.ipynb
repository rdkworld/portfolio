{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving for Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of data serving for analytics after an ETL transformation. Data retrieval and analysis is done with Amazon Athena, using simple SQL queries. The output is taken to build an interactive dashboard for exploring sales data by country and product line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install Cython\n",
    "# !pip install pandas\n",
    "# !pip install awswrangler\n",
    "# !pip install seaborn\n",
    "# !pip install ipywidgets\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the execution of the AWS Glue job, a new database named `de-c1w2-analytics-db` has been created. This database encompasses four tables with the following schema:\n",
    "\n",
    "![image alt ><](./images/schema_after_ETL.png)\n",
    "\n",
    "Your data is ready to be served for analytics. Amazon Athena enables the execution of simple SQL queries for retrieving data effortlessly. It simplifies the process of querying and analyzing data stored in various sources without the need for complex infrastructure management. Let's see the data stored in the `dim_products` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_DATABASE = \"de-c1w2-analytics-db\"\n",
    "\n",
    "products_df = wr.athena.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT * FROM dim_products\n",
    "    \"\"\",\n",
    "    database=GLUE_DATABASE,\n",
    ")\n",
    "    \n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get some data insights making your SQL query slightly more complicated. In the following cell you will sum the total cells by country and display the top 10 records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sales_by_country_df = wr.athena.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        dim_locations.country,\n",
    "        SUM(fact_orders.orderAmount) AS total_sales\n",
    "    FROM\n",
    "        fact_orders\n",
    "    JOIN\n",
    "        dim_locations ON fact_orders.postalCode = dim_locations.postalCode\n",
    "    GROUP BY 1\n",
    "    \"\"\",\n",
    "    database=GLUE_DATABASE,\n",
    ")\n",
    "    \n",
    "product_sales_by_country_df.sort_values(\"total_sales\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will combine data from three tables: `fact_orders`, `dim_products`, and `dim_locations`. The query will select the order date, product line, product name, country, and total sales amount, grouping the results by order date, product line, product name, and country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sales_df = wr.athena.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        fact_orders.orderDate,\n",
    "        dim_products.productLine,\n",
    "        dim_products.productName,\n",
    "        dim_locations.country,\n",
    "        SUM(fact_orders.orderAmount) AS total_sales\n",
    "    FROM\n",
    "        fact_orders\n",
    "    JOIN\n",
    "        dim_products ON fact_orders.productCode = dim_products.productCode\n",
    "    JOIN\n",
    "        dim_locations ON fact_orders.postalCode = dim_locations.postalCode\n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\",\n",
    "    database=GLUE_DATABASE,\n",
    ")\n",
    "    \n",
    "product_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be taken to build an interactive dashboard using dropdown widgets, where you will be able to select a country and product line. You can also filter only particular periods of sales, showing the top N popular products at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_widget = widgets.Dropdown(\n",
    "    options=[\"ALL\"] + sorted(list(product_sales_df.country.unique())),\n",
    "    value=\"ALL\",\n",
    "    description=\"Country\",\n",
    ")\n",
    "\n",
    "productline_widget = widgets.Dropdown(\n",
    "    options=[\"ALL\"] + sorted(list(product_sales_df.productline.unique())),\n",
    "    value=\"ALL\",\n",
    "    description=\"Product Line\",\n",
    ")\n",
    "\n",
    "@widgets.interact(\n",
    "    start_date=widgets.DatePicker(value=product_sales_df.orderdate.min(), description=\"Start Date\"),\n",
    "    end_date=widgets.DatePicker(value=product_sales_df.orderdate.max(), description=\"End Date\"),\n",
    "    country=country_widget,\n",
    "    productline=productline_widget,\n",
    "    top_n=widgets.IntSlider(value=5, min=1, max=10, step=1, description=\"Top N\"),\n",
    ")\n",
    "\n",
    "def plot_top_n_sales(start_date, end_date, country, productline, top_n):\n",
    "    filtered_df = product_sales_df[\n",
    "        (product_sales_df.orderdate >= pd.to_datetime(start_date))\n",
    "        & (product_sales_df.orderdate <= pd.to_datetime(end_date))\n",
    "    ]\n",
    "    \n",
    "    title_str = f\"Top {top_n} Popular \"\n",
    "    \n",
    "    if productline != \"ALL\":\n",
    "        filtered_df = filtered_df[filtered_df.productline == productline]\n",
    "        title_str += productline\n",
    "    else: \n",
    "        title_str += \"Products\"\n",
    "        \n",
    "    if country != \"ALL\":\n",
    "        filtered_df = filtered_df[filtered_df.country == country]\n",
    "        title_str += \" in \" + country\n",
    "    \n",
    "    if not (filtered_df.empty):\n",
    "        ax = sns.barplot(\n",
    "            x=\"total_sales\",\n",
    "            y=\"productname\",\n",
    "            data=filtered_df.head(top_n).sort_values(\"total_sales\", ascending=False),\n",
    "        )\n",
    "\n",
    "        ax.set(\n",
    "            xlabel=\"Total Sales\",\n",
    "            ylabel=\"Product Name\",\n",
    "            title=title_str\n",
    "        )\n",
    "    else:\n",
    "        print(f\"There were no sales of {productline} to {country} during that period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! You can now observe how effortlessly the data can be accessed following the completion of the ETL transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
