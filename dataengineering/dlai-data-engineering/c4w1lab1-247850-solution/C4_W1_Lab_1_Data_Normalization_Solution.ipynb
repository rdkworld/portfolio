{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6705e4-db90-4979-be94-bc2dcd871c44",
   "metadata": {},
   "source": [
    "# Week 1 Lab: Data Normalization\n",
    "\n",
    "In this lab, you will learn how to transform a database table from the \"One Big Table\" (OBT) form into the First Normal Form (1NF), Second Normal Form (2NF), and Third Normal Form (3NF). This process is fundamental to database normalization, which helps reduce data redundancy and improve data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761589e4-4b64-488f-9a21-4e6b0c560d97",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [ 1 - Introduction](#1)\n",
    "  - [ 1.1 - Data Normalization](#1.1)\n",
    "  - [ 1.2 - Dataset](#1.2)\n",
    "- [ 2 - First Normal Form (1NF)](#2)\n",
    "- [ 3 - Second Normal Form (2NF)](#3)\n",
    "- [ 4 - Third Normal Form (3NF)](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c8947-0e07-4968-8c36-ff4e37df0025",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Introduction\n",
    "\n",
    "As a Data Engineer, you may not frequently need to perform data normalization from scratch, but understanding the steps involved in this process is crucial. Typically, you will encounter source databases that are already normalized, and your task will often involve denormalizing this data to make it useful for extracting insights or solving business questions. This lab focuses on the opposite process: taking a dataset that has been loaded as a One Big Table and normalizing it up to the third normal form, which is common in transactional systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e459a9c-33da-4641-aa16-d2e56e2b4e38",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "### 1.1 - Data Normalization\n",
    "\n",
    "Normalization is a database design technique that organizes tables to minimize redundancy and dependency. It involves dividing large tables into smaller, less redundant tables and defining relationships between them. The goal is to isolate data so that additions, deletions, and modifications can be made in a single table and then propagated through the rest of the database using defined relationships.\n",
    "\n",
    "Some of the benefits of having a normalized set of tables are the following: \n",
    "- Reduce Data Redundancy: Eliminating duplicate data, which helps in saving storage space and ensures consistency across the database.\n",
    "- Improve Data Integrity: Ensuring that each piece of data is stored in only one place, reducing the likelihood of data anomalies and maintaining the accuracy of the data.\n",
    "- Enhance Query Performance: By organizing data into related tables, you have made it easier to query and manage the data, leading to better performance and easier maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36eb02-51a5-4cad-856b-77d41df06938",
   "metadata": {},
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Dataset\n",
    "\n",
    "The dataset that you are going to use is related to the typical [`classicmodels`](https://www.mysqltutorial.org/mysql-sample-database.aspx) dataset that you have used but has been transformed to generate One Big Table. The original data comes in a multiline JSON file where each JSON object has the following structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc156d6-d29e-4412-880f-cbdd03cc11d1",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"orderNumber\": 10100,\n",
    "  \"orderDate\": \"2003-01-06\",\n",
    "  \"requiredDate\": \"2003-01-13\",\n",
    "  \"shippedDate\": \"2003-01-10\",\n",
    "  \"status\": \"Shipped\",\n",
    "  \"comments\": null,\n",
    "  \"orderDetails\": [\n",
    "    {\n",
    "      \"productCode\": \"S18_1749\",\n",
    "      \"quantityOrdered\": 30,\n",
    "      \"priceEach\": 136.00\n",
    "    },\n",
    "    {\n",
    "      \"productCode\": \"S18_2248\",\n",
    "      \"quantityOrdered\": 50,\n",
    "      \"priceEach\": 55.09\n",
    "    },\n",
    "    {\n",
    "      \"productCode\": \"S18_4409\",\n",
    "      \"quantityOrdered\": 22,\n",
    "      \"priceEach\": 75.46\n",
    "    },\n",
    "    {\n",
    "      \"productCode\": \"S24_3969\",\n",
    "      \"quantityOrdered\": 49,\n",
    "      \"priceEach\": 35.29\n",
    "    }\n",
    "  ],\n",
    "  \"customer\": {\n",
    "    \"customerName\": \"Online Diecast Creations Co.\",\n",
    "    \"contactLastName\": \"Young\",\n",
    "    \"contactFirstName\": \"Dorothy\",\n",
    "    \"phone\": \"6035558647\",\n",
    "    \"addressLine1\": \"2304 Long Airport Avenue\",\n",
    "    \"addressLine2\": null,\n",
    "    \"city\": \"Nashua\",\n",
    "    \"state\": \"NH\",\n",
    "    \"postalCode\": \"62005\",\n",
    "    \"country\": \"USA\",\n",
    "    \"salesRepEmployeeNumber\": 1216.00,\n",
    "    \"creditLimit\": 114200.00\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1c208-f47c-41b7-b16b-522ae0a81fb6",
   "metadata": {},
   "source": [
    "This dataset has already been uploaded into the database that you are going to use by following this schema:\n",
    "\n",
    "![ERD_OBT](./images/ERD_OBT.png)\n",
    "\n",
    "As you can see, a schema named `classicmodels_obt` with a table named `orders` was added. Notice, that the `orderDetails` and `customer` fields have been saved as JSON objects directly in the database, they are structured as a dictionary with key-value pairs holding information about each order and customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8a4fb-7a52-4f26-b6c5-1b143185161c",
   "metadata": {},
   "source": [
    "To explore the data, let's import all the necessary packages and SQL extensions for running the `%sql` magic commands used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d6493-afc8-4e46-84f0-ac177edf8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256d614-365c-40de-ab6e-615a4af08ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d10ebf",
   "metadata": {},
   "source": [
    "In the AWS console, go to **CloudFormation** where two stacks have already been deployed. One is associated with your Cloud environment with a name prefix `aws-cloud9`; and another with an alphanumeric ID. Click on the alphanumeric ID stack and it will take you to another screen page with details about this stack. In the **Outputs** tab, you will see the key `PostgresEndpoint` and its corresponding **Value** column. Copy the value and edit the `./src/env` file, replacing the placeholder `<RDS-ENDPOINT>` with the endpoint value. Save changes to the file.\n",
    "\n",
    "Execute the following cell to load the environment variables and connect to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('./src/env', override=True)\n",
    "\n",
    "DBHOST = os.getenv('DBHOST')\n",
    "DBPORT = os.getenv('DBPORT')\n",
    "DBNAME = os.getenv('DBNAME')\n",
    "DBUSER = os.getenv('DBUSER')\n",
    "DBPASSWORD = os.getenv('DBPASSWORD')\n",
    "\n",
    "connection_url = f\"postgresql+psycopg2://{DBUSER}:{DBPASSWORD}@{DBHOST}:{DBPORT}/{DBNAME}\"\n",
    "\n",
    "%sql {connection_url}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c113d-a833-452b-835f-7f3d372140b2",
   "metadata": {},
   "source": [
    "Explore the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6f294-9293-49c6-9f66-6107011d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from classicmodels_obt.orders;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16712591-1b8e-4a7c-a8a5-669c47c17777",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from classicmodels_obt.orders limit 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93704eee-21dd-4221-aae0-1a1e32372bea",
   "metadata": {},
   "source": [
    "The dataset has been generated into a One Big Table (OBT) from a multiline JSON file, consolidating all data into a single dataset for query processing. The `orderdetails` and `customer` fields are not basic data types, they are dictionaries with the following structure:\n",
    "\n",
    "- `orderdetails` is a list of dictionaries/JSON objects about all the products under an individual order. Each entry on the list refers to a product, with keys on its product code, the quantity ordered and the unitary price.\n",
    "\n",
    "- `customer` field contains a dictionary/JSON object where each key corresponds to a feature of the customer that placed the order, this includes information on personal details, contact, and location.\n",
    "\n",
    "Now you will perform some basic transformations to the dataset to achieve the three different normal forms and separate the data in each form in a different schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c416b73-70f9-4369-82d1-70b0c978fa93",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - First Normal Form (1NF)\n",
    "\n",
    "Your first task is to create a First Normal Form (1NF) of this dataset and insert it into the database. For that, you will read the data using an SQL query and will transform the data using `pandas` package. \n",
    "\n",
    "The feature of the First Normal Form is that a relation in this form does not contain any multi-valued field. That means that each attribute/field/column contains only atomic or single values.\n",
    "\n",
    "Given the current form that our dataset has, in order to achieve a 1NF you need to unnest the `orderdetails` list and for each element, you will create a row. In addition, as each element is a JSON object or dictionary (which is a multi-valued field), you also have to unnest the data and create a new field or column for each key inside this dictionary. This last step needs to be replicated in the `customer` JSON object field.\n",
    "\n",
    "The final schema after the 1NF will look like the following image \n",
    "\n",
    "![ERD_1NF_orders](./images/ERD_1NF_Orders.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e93943-4a99-4758-986f-ac0775eb7c03",
   "metadata": {},
   "source": [
    "2.1. Create the schema in which the relations in 1NF will be stored and then read the OBT dataset and save it as a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660c87e-08d2-42f7-8115-7e314f6bcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE SCHEMA IF NOT EXISTS classicmodels_1nf;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cfbf5-c3a9-4946-9b64-7e19edff2a9f",
   "metadata": {},
   "source": [
    "Have a look again at the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd13aa-7c0b-4816-97eb-9729a6b94988",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql select * from classicmodels_obt.orders\n",
    "\n",
    "df = result.DataFrame()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e167d2-8a3e-4bb5-aac4-301f18909e9c",
   "metadata": {},
   "source": [
    "2.2. Create a new flat table with the dictionaries extracted from the `customer` field of the `df` dataframe. You can use the `pandas` [`json_normalize()` method](https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html) over the `customer` field for this purpose. This function will return a dataframe with the key-value pairs as columns of the new table.\n",
    "\n",
    "*Note*: In the cells where you see the comments `### START CODE HERE ###` and `### END CODE HERE ###` you need to complete the code replacing all `None`. The rest of the cells are already complete, you just need to review and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de17bc4-7fb0-4cb3-a07c-01ffb56b0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line of code)\n",
    "customers_df = pd.json_normalize(df['customer']) # @REPLACE EQUALS pd.None(None['None'])\n",
    "### END CODE HERE ###\n",
    "\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be37ab8-94bb-4c9c-83fc-d2fbd375adec",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **city**    | **phone**         | **state** | **country** | **postalCode** | **creditLimit** | **addressLine1**           | **addressLine2** | **customerName**              | **contactLastName** | **contactFirstName** | **salesRepEmployeeNumber** |\r\n",
    "| ----------- | ----------------- | --------- | ----------- | -------------- | --------------- | -------------------------- | ---------------- | ----------------------------- | ------------------- | ------------------- | ------------------------ |\r\n",
    "| Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   |\r\n",
    "| Frankfurt   | +49 69 66 90 2555 | None      | Germany     | 60528          | 59700.0         | Lyonerstr. 34              | None             | Blauer See Auto, Co.          | Keitel              | Roland               | 1504.0                   |\r\n",
    "| NYC         | 2125551500        | NY        | USA         | 10022          | 76400.0         | 2678 Kingston Rd.          | Suite 101        | Vitachrome Inc.               | Frick               | Michael              | 1286.0                   |\r\n",
    "| Stavern     | 07-98 9555        | None      | Norway      | 4110           | 81700.0         | Erling Skakkes gate 78     | None             | Baane Mini Imports            | Bergulfsen          | Jonas                | 1504.0                   |\r\n",
    "| Madrid      | (91) 555 94 44    | None      | Spain       | 28034          | 227600.0        | C/ Moralzarzal, 86         | None             | Euro+ Shopping Channel        | Freyre              | Diego                | 1370.0                  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e95479-b262-4883-9854-5bae3a204aa4",
   "metadata": {},
   "source": [
    "`pd.json_normalize` creates a DataFrame where each dictionary in the `customer` column is flattened into a row. The index of the original DataFrame is preserved, which is crucial for maintaining the correct relationship between the original rows and the new flattened rows. It is time to concatenate the two datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d688b28-ace7-40f1-b5a9-9cc254b99b9c",
   "metadata": {},
   "source": [
    "2.3. You need to drop the `customer` column from the original dataframe, using `drop()` method and specifying the column. You should keep `inplace` argument equal to `True`. \n",
    "\n",
    "Then concatenate the dataframe `df` with `customers_df`. For that, you will use `pd.concat` method with the `axis` parameter set as 1. Using `pd.concat` with `axis=1` joins the DataFrames column-wise, aligning rows by their index. Since the index is preserved, each row in the flattened `customers_df` dataframe aligns correctly with its corresponding row in the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae1056-7955-4287-85bf-1b2200f35fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (2 lines of code)\n",
    "df.drop(columns='customer', inplace=True) # @REPLACE df.None(columns='None', inplace=True)\n",
    "df = pd.concat([df, customers_df], axis=1) # @REPLACE EQUALS pd.None([df, None], axis=1)\n",
    "### END CODE HERE ###\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611ab1a-5cda-49b6-b670-dbd8e89fb6e5",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "*Note*: Some text is omitted.\n",
    "\n",
    "| **ordernumber** | **orderdate** | **requireddate** | **shippeddate** | **status** | **comments**             | **orderdetails** | **city**    | **phone**         | **state** | **country** | **postalCode** | **creditLimit** | **addressLine1**           | **addressLine2** | **customerName**              | **contactLastName** | **contactFirstName** | **salesRepEmployeeNumber** |\r\n",
    "| --------------- | ------------- | ---------------- | --------------- | ---------- | ----------------------- | ---------------- | ----------- | ----------------- | --------- | ----------- | -------------- | --------------- | -------------------------- | ---------------- | ----------------------------- | ------------------- | ------------------- | ------------------------ |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                    | text...          | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   |\r\n",
    "| 10101           | 2003-01-09    | 2003-01-18       | 2003-01-11      | Shipped    | Check on availability.  | text...          | Frankfurt   | +49 69 66 90 2555 | None      | Germany     | 60528          | 59700.0         | Lyonerstr. 34              | None             | Blauer See Auto, Co.          | Keitel              | Roland               | 1504.0                   |\r\n",
    "| 10102           | 2003-01-10    | 2003-01-18       | 2003-01-14      | Shipped    | None                    | text...          | NYC         | 2125551500        | NY        | USA         | 10022          | 76400.0         | 2678 Kingston Rd.          | Suite 101        | Vitachrome Inc.               | Frick               | Michael              | 1286.0                   |\r\n",
    "| 10103           | 2003-01-29    | 2003-02-07       | 2003-02-02      | Shipped    | None                    | text...          | Stavern     | 07-98 9555        | None      | Norway      | 4110           | 81700.0         | Erling Skakkes gate 78     | None             | Baane Mini Imports            | Bergulfsen          | Jonas                | 1504.0                   |\r\n",
    "| 10104           | 2003-01-31    | 2003-02-09       | 2003-02-01      | Shipped    | None                    | text...          | Madrid      | (91) 555 94 44    | None      | Spain       | 28034          | 227600.0        | C/ Moralzarzal, 86         | None             | Euro+ Shopping Channel        | Freyre              | Diego                | 1370.0                  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed6185-d086-46c3-9254-ade02914d35e",
   "metadata": {},
   "source": [
    "2.4. Add an ID column with each entry holding a unique identifier for each customer in addition to the customer's name. (The code below is complete; no change is required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02c4b0-5224-43bf-be69-d6f6bffc5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customerNumber'] = pd.factorize(df['customerName'])[0] + 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dc3af-cc9c-44d8-b3cd-c9d11699def4",
   "metadata": {},
   "source": [
    "Now that the `customer` field has been transformed into atomic-valued fields, you need to do the same for the `orderdetails` column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6be02d-fc5e-47ae-93e8-797c36be26a9",
   "metadata": {},
   "source": [
    "2.5. Create a new row for each product in the same order using the `pandas` [`explode()` method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.explode.html) on `orderdetails` column of the original `df` dataframe. Make sure to set the `ignore_index` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3d3da-cdf1-45c5-bf25-9637fb2298d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line of code)\n",
    "df_exploded = df.explode('orderdetails', ignore_index=True) # @REPLACE EQUALS df.None('None', ignore_index=None)\n",
    "### END CODE HERE ###\n",
    "\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c085c73-f21f-4b38-b6ed-e9b77d3fbe2f",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **ordernumber** | **orderdate** | **requireddate** | **shippeddate** | **status** | **comments**            | **orderdetails** | **city**    | **phone**         | **state** | **country** | **postalCode** | **creditLimit** | **addressLine1**           | **addressLine2** | **customerName**              | **contactLastName** | **contactFirstName** | **salesRepEmployeeNumber** | **customerNumber** |\r\n",
    "| --------------- | ------------- | ---------------- | --------------- | ---------- | ---------------------- | ---------------- | ----------- | ----------------- | --------- | ----------- | -------------- | --------------- | -------------------------- | ---------------- | ----------------------------- | ------------------- | ------------------- | ------------------------ | ------------------ |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | text...          | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | text...          | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | text...          | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | text...          | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  |\r\n",
    "| 10101           | 2003-01-09    | 2003-01-18       | 2003-01-11      | Shipped    | Check on availability. | text...          | Frankfurt   | +49 69 66 90 2555 | None      | Germany     | 60528          | 59700.0         | Lyonerstr. 34              | None             | Blauer See Auto, Co.          | Keitel              | Roland               | 1504.0                   | 2                  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12feafa1-bc37-4e84-98f3-79cf836cfc58",
   "metadata": {},
   "source": [
    "The `explode` function is used to transform each element of a list-like column into a separate row. Setting `ignore_index=True` resets the index of the resulting dataframe, creating a new integer index that starts from 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee37d6-be2c-45ec-ba9c-50e9830d017f",
   "metadata": {},
   "source": [
    "2.6. Use again the `json_normalize` over the `orderdetails` column of the dataframe `df_exploded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf75a3-813f-4705-82f2-4a2a5588c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line of code)\n",
    "orderdetails_normalized = pd.json_normalize(df_exploded['orderdetails']) # @REPLACE EQUALS pd.None(None['None'])\n",
    "### END CODE HERE ###\n",
    "\n",
    "orderdetails_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317ecd6-2d50-4534-9ffb-85c52c257809",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **priceEach** | **productCode** | **quantityOrdered** |\r\n",
    "| ------------- | --------------- | ------------------- |\r\n",
    "| 136.00        | S18_1749        | 30                  |\r\n",
    "| 55.09         | S18_2248        | 50                  |\r\n",
    "| 75.46         | S18_4409        | 22                  |\r\n",
    "| 35.29         | S24_3969        | 49                  |\r\n",
    "| 108.06        | S18_2325        | 25                 |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1d3ad",
   "metadata": {},
   "source": [
    "2.7. Finally, `drop()` the `orderdetails` column from the original `df_exploded` dataframe keeping `inplace` argument equal to `True`.  Then `concat()` `df_exploded` dataframe with the `orderdetails_normalized` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316445a5-99e5-4906-9e0e-016b43534219",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (2 lines of code)\n",
    "df_exploded.drop(columns='orderdetails', inplace=True) # @REPLACE df_exploded.None(columns='None', inplace=True)\n",
    "df_normalized = pd.concat([df_exploded, orderdetails_normalized], axis=1) # @REPLACE EQUALS pd.None([df_exploded, None], axis=1)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# First Normal Form\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49b67f-1412-412b-b015-621482ce9467",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **ordernumber** | **orderdate** | **requireddate** | **shippeddate** | **status** | **comments**            | **city**    | **phone**         | **state** | **country** | **postalCode** | **creditLimit** | **addressLine1**           | **addressLine2** | **customerName**              | **contactLastName** | **contactFirstName** | **salesRepEmployeeNumber** | **customerNumber** | **priceEach** | **productCode** | **quantityOrdered** |\r\n",
    "| --------------- | ------------- | ---------------- | --------------- | ---------- | ---------------------- | ----------- | ----------------- | --------- | ----------- | -------------- | --------------- | -------------------------- | ---------------- | ----------------------------- | ------------------- | ------------------- | ------------------------ | ------------------ | ------------ | --------------- | ------------------- |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  | 136.00        | S18_1749        | 30                  |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  | 55.09         | S18_2248        | 50                  |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  | 75.46         | S18_4409        | 22                  |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                   | Nashua      | 6035558647        | NH        | USA         | 62005          | 114200.0        | 2304 Long Airport Avenue   | None             | Online Diecast Creations Co.  | Young               | Dorothy              | 1216.0                   | 1                  | 35.29         | S24_3969        | 49                  |\r\n",
    "| 10101           | 2003-01-09    | 2003-01-18       | 2003-01-11      | Shipped    | Check on availability. | Frankfurt   | +49 69 66 90 2555 | None      | Germany     | 60528          | 59700.0         | Lyonerstr. 34              | None             | Blauer See Auto, Co.          | Keitel              | Roland               | 1504.0                   | 2                  | 108.06        | S18_2325        | 25                  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add7a718-d52b-43bc-8144-7808b4c67b1a",
   "metadata": {},
   "source": [
    "The resulting dataframe `df_normalized` should be in the Frist Normal Form now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654d61e-309d-4bd2-9217-0d1d893ac8cd",
   "metadata": {},
   "source": [
    "2.8. Now that you have atomic values in your dataset, let's create an additional identifier for each product in each order. You will call it Order Line Number (`orderlinenumber`) and in combination with the `ordernumber` column, they will create a composite primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f856e7a-c7c0-415c-bb20-f082d406e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized['orderlinenumber'] = df_normalized.groupby('ordernumber').cumcount() + 1\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bc34a-1e33-4401-9ad9-73e8746224b5",
   "metadata": {},
   "source": [
    "2.9. With those transformations, you have finished your normalization up to 1NF. Let's insert this dataset into your database. Drop the table if it has been loaded before to avoid an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ccd40-4119-4098-939a-638561c74748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS classicmodels_1nf.orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd1d523-020f-4401-a800-7062aec7bc5d",
   "metadata": {},
   "source": [
    "Create table named `orders` in the schema `classicmodels_1nf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa4e993-6d50-4736-a00b-6235a4b69fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(connection_url)\n",
    "\n",
    "df_normalized.to_sql('orders', engine, schema='classicmodels_1nf', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a302c29d",
   "metadata": {},
   "source": [
    "Inspect the data that you just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cc283-ab1e-4a04-8bed-34893682d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT COUNT(*) FROM classicmodels_1nf.orders;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b345337-b069-4a0e-af02-48a3a8242eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT * FROM classicmodels_1nf.orders LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7e094-071a-458a-ba55-4fc8363496fb",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Second Normal Form (2NF)\n",
    "\n",
    "In the second normal form (2NF), data must already be in the first normal form (1NF), and all non-key attributes must be fully functionally dependent on the primary key.\n",
    " \n",
    "Here, by using the `ordernumber` and `orderlinenumber` columns as a composite primary key, you will create a unique identifier for each order line. \n",
    "Additionally, you have a separate identifier for customers along with their complete information. Since it's unnecessary to include all customer details in the same row as the order, you only need the customer identifier in the order table. The complete customer information can be moved to a separate table that is fully functional and dependent only on the customer identifier. \n",
    "\n",
    "The final schema after the 2NF transformations will look like this:\n",
    "\n",
    "![ERD_2NF](./images/ERD_2NF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61f476-edb9-4be3-9703-158b11a8163d",
   "metadata": {},
   "source": [
    "3.1. Create the `classicmodels_2nf` schema to store our tables and then read the 1NF dataset and transform it to create a 2NF version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290f76a-4928-4e28-a523-4b0fe4531c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE SCHEMA IF NOT EXISTS classicmodels_2nf;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b751f-4c04-44f1-9d94-60fdbac9cc30",
   "metadata": {},
   "source": [
    "Have a look again at the data in the 1NF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c5ab5-28c4-46b9-92f1-b30d533c44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql select * from classicmodels_1nf.orders\n",
    "df_orders = result.DataFrame()\n",
    "\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8387937-610c-4129-a88f-cda7d0774c37",
   "metadata": {},
   "source": [
    "3.2. Extract all the information related to customers and create a table with the unique values for each customer. \n",
    "- Take only customer related columns from your `df_orders` dataframe (see the list in the cell below) and make a copy of it with the `copy()` method naming it `df_customers`.\n",
    "- Take the dataframe that you just have copied and drop the duplicated rows using the method `drop_duplicates`. Make sure that you put argument `inplace` equal to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc9971-4bf0-4d46-879b-1a4f9e561649",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_columns = ['customerNumber', \n",
    "                    'customerName', \n",
    "                    'contactLastName', \n",
    "                    'contactFirstName', \n",
    "                    'phone', \n",
    "                    'addressLine1', \n",
    "                    'addressLine2',\n",
    "                    'postalCode',                     \n",
    "                    'city', \n",
    "                    'state', \n",
    "                    'country', \n",
    "                    'creditLimit',\n",
    "                    'salesRepEmployeeNumber',\n",
    "                   ] \n",
    "\n",
    "### START CODE HERE ### (2 lines of code)\n",
    "df_customers = df_orders[customer_columns].copy() # @REPLACE EQUALS None[None].None()\n",
    "df_customers.drop_duplicates(inplace=True) # @REPLACE None.None(inplace=None)\n",
    "### END CODE HERE ###\n",
    "\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc191c25-cd01-440e-8d02-6f3f1b503fbb",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **customerNumber** | **customerName**                | **contactLastName** | **contactFirstName** | **phone**         | **addressLine1**           | **addressLine2** | **postalCode** | **city**  | **state** | **country** | **creditLimit** | **salesRepEmployeeNumber** |\r\n",
    "| ------------------ | -------------------------------- | ------------------- | ------------------- | ----------------- | -------------------------- | ---------------- | -------------- | -------- | --------- | ----------- | --------------- | ------------------------- |\r\n",
    "| 1                  | Online Diecast Creations Co.   | Young               | Dorothy             | 6035558647        | 2304 Long Airport Avenue   | None             | 62005          | Nashua   | NH        | USA         | 114200.0        | 1216.0                    |\r\n",
    "| 2                  | Blauer See Auto, Co.            | Keitel              | Roland              | +49 69 66 90 2555 | Lyonerstr. 34              | None             | 60528          | Frankfurt | None      | Germany     | 59700.0         | 1504.0                    |\r\n",
    "| 3                  | Vitachrome Inc.                 | Frick                | Michael             | 2125551500        | 2678 Kingston Rd.         | Suite 101        | 10022          | NYC      | NY        | USA         | 76400.0         | 1286.0                    |\r\n",
    "| 4                  | Baane Mini Imports              | Bergulfsen           | Jonas               | 07-98 9555        | Erling Skakkes gate 78    | None             | 4110           | Stavern  | None      | Norway      | 81700.0         | 1504.0                    |\r\n",
    "| 5                  | Euro+ Shopping Channel         | Freyre              | Diego               | (91) 555 94 44   | C/ Moralzarzal, 86        | None             | 28034          | Madrid  | None      | Spain       | 227600.0        | 1370.0                    |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36798d8-79a2-4982-a5e6-c469ef526075",
   "metadata": {},
   "source": [
    "3.3. Now that you have your customers' dataset, that information can be dropped from the original dataframe. The only necessary column to keep is the `customerNumber` as it helps to relate the orders with customers' information. Create a list of the columns which you need to drop from the `df_orders` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b53a0f-2ee9-4333-9748-cb5107e12839",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_columns.pop(0)\n",
    "customer_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cbcfb-739c-4d67-90b0-55585b865844",
   "metadata": {},
   "source": [
    "3.4. Drop the `customer_columns` from the dataframe `df_orders`. The `inplace` argument should be equal to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424313b8-603d-473b-a131-87444a3b652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (1 line of code)\n",
    "df_orders.drop(columns=customer_columns, inplace=True) # @REPLACE None.None(columns=None, inplace=None)\n",
    "### END CODE HERE ###\n",
    "\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92a745-ae01-4acd-ae4d-533fbb1aa9b5",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **ordernumber** | **orderdate** | **requireddate** | **shippeddate** | **status** | **comments**             | **customerNumber** | **priceEach** | **productCode** | **quantityOrdered** | **orderlinenumber** |\r\n",
    "| ---------------- | ------------- | ---------------- | --------------- | ---------- | ------------------------ | ------------------- | ------------ | --------------- | ------------------- | ------------------- |\r\n",
    "| 10100            | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                     | 1                   | 136.00       | S18_1749        | 30                  | 1                   |\r\n",
    "| 10100            | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                     | 1                   | 55.09        | S18_2248        | 50                  | 2                   |\r\n",
    "| 10100            | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                     | 1                   | 75.46        | S18_4409        | 22                  | 3                   |\r\n",
    "| 10100            | 2003-01-06    | 2003-01-13       | 2003-01-10      | Shipped    | None                     | 1                   | 35.29        | S24_3969        | 49                  | 4                   |\r\n",
    "| 10101            | 2003-01-09    | 2003-01-18       | 2003-01-11      | Shipped    | Check on availability.  | 2                   | 108.06       | S18_2325        | 25                  | 1                   |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83558ace-13d2-4aec-b111-89a997f6db67",
   "metadata": {},
   "source": [
    "You have created 2NF version of the relations. The result of this normalization step is two datasets or entities:\n",
    "- `orders`: Containing only the information about each order.\n",
    "- `customers`: Containing only the complete information about the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c4012-2c04-4e72-aaac-aa4b5f22be1c",
   "metadata": {},
   "source": [
    "3.5. The two previous entities can be related through the `customerNumber` field. Insert the two previous tables into the `classicmodels_2nf` schema. You will need to drop the tables before that in case they have been added before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3dff6-31da-47ed-943d-91963c18181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS classicmodels_2nf.orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fe00f-f5fa-4d04-b8d7-7bcb320c6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS classicmodels_2nf.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f527026-22f8-411a-bb9e-74f1ba7a74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.to_sql('orders', engine, schema='classicmodels_2nf', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaffa6a-38f3-4f6f-a701-f9f7e18e4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.to_sql('customers', engine, schema='classicmodels_2nf', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c12a44-aae7-4387-9a55-c1f92399065e",
   "metadata": {},
   "source": [
    "Explore the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be780032",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM classicmodels_2nf.orders;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(*) FROM classicmodels_2nf.customers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM classicmodels_2nf.customers limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0056649",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM classicmodels_2nf.orders limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddeb4b-e0d9-4294-917e-b240ef6a5112",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Third Normal Form (3NF)\n",
    "\n",
    "The features of 3NF are the following:\n",
    "- Already in 2NF: The table must already be in Second Normal Form (2NF).\n",
    "- No Transitive Dependencies: There should be no transitive dependencies between non-prime attributes. In other words, non-prime attributes (attributes that are not part of any candidate key should not depend on other non-prime attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd2acf-dad9-4f7b-852a-b1187d854623",
   "metadata": {},
   "source": [
    "In the `orders` table you have the following columns: `ordernumber`, `orderdate`, `requireddate`, `shippeddate`, `status`, `comments`, `customerNumber`, `priceEach`, `productCode`, `quantityOrdered`, and `orderlinenumber`.\n",
    "\n",
    "Let's identify Transitive Dependencies:\n",
    "\n",
    "- Columns `orderdate`, `requireddate`, `shippeddate`, `status`, `comments`, `salesRepEmployeeNumber`, and `customerNumber` are dependent on `ordernumber`.\n",
    "- Columns `productCode`, `priceEach`, and `quantityOrdered` depend on the composite key (`ordernumber`, `orderlinenumber`).\n",
    "\n",
    "You can see that columns related with order-level information such as dates, `comments` or even `customerNumber` depend only on `ordernumber`, which given that is part of the composite key (`ordernumber`, `orderlinenumber`), make those order-level fields to also depend on the composite key, and in particular on the `orderlinenumber` field. This is a transitive relationship that you should get rid of to achieve 3NF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9771072-d413-43a1-8834-6dfb855f411c",
   "metadata": {},
   "source": [
    "To transform the relations into 3NF, you need to separate the table into two: one for order-level information and another for order line items or order details.\n",
    "\n",
    "- **Order Table:**\n",
    "    * Primary Key: `ordernumber`\n",
    "    * Attributes: `orderdate`, `requireddate`, `shippeddate`, `status`, `comments`, `salesRepEmployeeNumber`, `customerNumber`.\n",
    "\n",
    "- **Order Details Table:**\n",
    "    * Composite Primary Key: (`ordernumber`, `orderlinenumber`)\n",
    "    * Attributes: `productCode`, `priceEach`, `quantityOrdered`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51126c-ddc7-4ed5-9d2a-c34da032c06a",
   "metadata": {},
   "source": [
    "By organizing the data this way, you can ensure that each non-prime attribute depends only on the primary key, achieving 3NF. Let's do it and upload our tables in the third normal form. \n",
    "\n",
    "The final result of the 3NF normalization is the following\n",
    "\n",
    "![ERD_3NF](./images/ERD_3NF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65b87f-8849-41ab-86be-19904f4161ec",
   "metadata": {},
   "source": [
    "4.1. Create the `classicmodels_3nf` schema to store your transformed tables there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592e27e-fb86-415e-9676-d1587524efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE SCHEMA IF NOT EXISTS classicmodels_3nf;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b27df",
   "metadata": {},
   "source": [
    "4.2. You will need to read the `orders` and `customers` tables from the `classicmodels_2nf` schema. Although you will not make any further changes to the `customers` table in this step, you will upload it into the 3NF schema to keep all your datasets in the same place.\n",
    "\n",
    "Read the `orders` table into the `df_orders` pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78587b-646e-4b81-bdef-d55c752be7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql select * from classicmodels_2nf.orders\n",
    "df_orders = result.DataFrame()\n",
    "\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30710ac",
   "metadata": {},
   "source": [
    "Read the `customers` table into `df_customers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f1ffc-d9b4-4756-8c1a-01e67dda3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql select * from classicmodels_2nf.customers\n",
    "df_customers = result.DataFrame()\n",
    "\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641dbbf",
   "metadata": {},
   "source": [
    "4.3. In order to separate the `classicmodels_2nf.orders` table into the `orderdetails` and the `order` table for the 3NF, let's extract the columns `columns_order_details` creating the `orderdetails` dataframe as a copy from `df_orders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6ff9e-2bfe-4e03-b31a-b4a145992235",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order_details = [\"ordernumber\",  \"orderlinenumber\", \"productCode\", \"quantityOrdered\", \"priceEach\"]\n",
    "\n",
    "### START CODE HERE ### (1 line of code)\n",
    "df_orderdetails = df_orders[columns_order_details].copy() # @REPLACE EQUALS None[None].None()\n",
    "### END CODE HERE ###\n",
    "\n",
    "df_orderdetails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0839bb5-b0e0-4205-87a4-c65e9ed20ed5",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **ordernumber** | **orderlinenumber** | **productCode** | **quantityOrdered** | **priceEach** |\r\n",
    "| --------------- | -------------------- | --------------- | -------------------- | ------------ |\r\n",
    "| 10100           | 1                    | S18_1749        | 30                   | 136.00       |\r\n",
    "| 10100           | 2                    | S18_2248        | 50                   | 55.09        |\r\n",
    "| 10100           | 3                    | S18_4409        | 22                   | 75.46        |\r\n",
    "| 10100           | 4                    | S24_3969        | 49                   | 35.29        |\r\n",
    "| 10101           | 1                    | S18_2325        | 25                   | 108.06      |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8b8ca",
   "metadata": {},
   "source": [
    "4.4. Create a list of the columns which you need to drop from the `df_orders` dataframe - the ones associated with the `orderdetails` table. You will keep the `ordernumber` field as it is the key to relating the two tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea53417-f809-489f-8329-e658f14d90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_order_details.pop(0)\n",
    "columns_order_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46932004-3357-498a-9ee0-7435f6a046d7",
   "metadata": {},
   "source": [
    "4.5. Create the `df_orders` table with only the necessary columns, dropping the columns specified in the list `columns_order_details`. Then drop the duplicated rows with the method `drop_duplicates()`. You should keep `inplace` argument equal to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073340d-9ac2-4b74-a42e-56971a059d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (2 lines of code)\n",
    "df_orders.drop(columns=columns_order_details, inplace=True) # @REPLACE None.None(columns=None, inplace=None)\n",
    "df_orders.drop_duplicates(inplace=True) # @REPLACE None.None(inplace=None)\n",
    "### END CODE HERE ###\n",
    "\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0a71c1-2525-4acd-ba26-4224d2dc8477",
   "metadata": {},
   "source": [
    "##### __Expected Output__\n",
    "\n",
    "| **ordernumber** | **orderdate** | **requireddate** | **shippeddate** | **status** | **comments**             | **customerNumber** |\r\n",
    "| --------------- | ------------- | ---------------- | ---------------- | ---------- | ----------------------- | ------------------ |\r\n",
    "| 10100           | 2003-01-06    | 2003-01-13       | 2003-01-10       | Shipped    | None                     | 1                  |\r\n",
    "| 10101           | 2003-01-09    | 2003-01-18       | 2003-01-11       | Shipped    | Check on availability.  | 2                  |\r\n",
    "| 10102           | 2003-01-10    | 2003-01-18       | 2003-01-14       | Shipped    | None                     | 3                  |\r\n",
    "| 10103           | 2003-01-29    | 2003-02-07       | 2003-02-02       | Shipped    | None                     | 4                  |\r\n",
    "| 10104           | 2003-01-31    | 2003-02-09       | 2003-02-01       | Shipped    | None                     | 5                  |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911962f6-d87d-489a-a405-ef36d3d37faa",
   "metadata": {},
   "source": [
    "Great! With those transformations you have achieved a 3NF from your initial OBT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b028ec2-adb3-4fb5-942b-78b73c3fefb2",
   "metadata": {},
   "source": [
    "4.6. Let's upload the data into the `classicmodels_3nf` schema. Remember that you have three tables: `customers`, `orders` and `orderdetails`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc242fc-a042-48aa-8641-8e9394c95f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS classicmodels_3nf.customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfc225-6e90-4c01-b2a4-87c2779f508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS classicmodels_3nf.orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6812b24-ca2c-457d-bd7b-34b31ee3fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS classicmodels_3nf.orderdetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aefd68-aca1-4a74-a58b-f66f338f260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.to_sql('customers', engine, schema='classicmodels_3nf', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943847f4-5fe4-40ac-952f-bb6b3277ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.to_sql('orders', engine, schema='classicmodels_3nf', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a3b8f-7a85-47ae-9690-f77328963b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orderdetails.to_sql('orderdetails', engine, schema='classicmodels_3nf', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70616129",
   "metadata": {},
   "source": [
    "Finally, you can take a look to each of the tables that have been stored in your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b6823-d5c7-49c8-ac4d-1f8036ee1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from classicmodels_3nf.customers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddf56c-94f1-4a00-8827-df9905cde210",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from classicmodels_3nf.orders;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63163ee-c5f9-4717-befd-dd814497434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select count(*) from classicmodels_3nf.orderdetails;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21aa10a-f5cb-4c49-86dd-1e2f10a5797c",
   "metadata": {},
   "source": [
    "In this lab, you have successfully transformed a One Big Table (OBT) into First Normal Form (1NF), Second Normal Form (2NF), and Third Normal Form (3NF). This process of normalization is crucial in designing efficient and reliable databases.\n",
    "\n",
    "Throughout the lab, you have learned the importance of each normal form and the specific steps required to achieve them:\n",
    "\n",
    "* 1NF: Ensuring that each table cell contains only atomic (indivisible) values and each record is unique.\n",
    "* 2NF: Building on 1NF by removing partial dependencies, ensuring that non-key attributes are fully dependent on the primary key.\n",
    "* 3NF: Further refining the table structure by removing transitive dependencies, ensuring that non-key attributes are dependent only on the primary key.\n",
    "\n",
    "This lab has provided you with hands-on experience in transforming a dataset into a normalized form, highlighting the practical steps and considerations involved in database normalization. As you progress in your work as a Data Engineer, these skills will be invaluable in ensuring the quality and efficiency of the databases you design and maintain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb1f8c-c1d3-4efe-8a69-85eefa283646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
